lora:
  r: 16
  alpha: 64
  dropout: 0.03
  merge_weights: False
  target_modules: ["q_proj", "v_proj", "k_proj", "out_proj"]
